apiVersion: v1
kind: ConfigMap
metadata:
  name: librechat-yaml
data:
  librechat.yaml: |
    version: 1.3.3
    cache: true
    endpoints:
      custom:
        - name: "Local Gateway"
          apiKey: "${OPENAI_API_KEY}"
          baseURL: "http://llm-gateway.ai.svc.cluster.local:4000/v1/chat/completions"
          directEndpoint: true
          models:
            default:
              - "GLM-4.7-Flash"
              - "Qwen3-Coder-30B-A3B-Instruct"
              - "gpt-oss-20b"
              - "gemma-3-12b-it"
              - "Qwen3-Coder-Next"
            fetch: false
          titleConvo: true
          titleModel: "GLM-4.7-Flash"
          modelDisplayLabel: "llama.cpp"
